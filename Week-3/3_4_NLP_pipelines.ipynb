{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» UnpackAI DL201 Bootcamp - Week 3 - NLP pipelines\n",
    "\n",
    "### ðŸ“• Learning Objectives\n",
    "\n",
    "* Getting working examples able to achieve the main NLP tasks\n",
    "* Knowing the existence of Hugging Face and the strenth of its pre-trained models and all-in-one pipelines\n",
    "\n",
    "### ðŸ“– Concepts map\n",
    "\n",
    "* Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import (use not verbose mode : ex \"import -Uqq pandas as pd\" if you are sure that there is no dependency error)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR is a directory, its path is ..\\data\n",
      "IMAGE_DIR is a directory, its path is ..\\img\n"
     ]
    }
   ],
   "source": [
    "# import data and images if necessary, and choose the right path\n",
    "is_kaggle = False   # True if you are on Kaggle, False for local Windows, Linux or Mac environments.\n",
    "\n",
    "if is_kaggle:\n",
    "    !pip install -Uqq transformers==4.10.2\n",
    "    IMAGE_DIR = Path('/kaggle/working/DL201/img')\n",
    "    DATA_DIR = Path('/kaggle/working/DL201/data')\n",
    "else:\n",
    "    # This section is for local execution, it is assumed that the notebook is on the 'Week-2' folder\n",
    "    # of the DL201 repository.\n",
    "    DATA_DIR = Path('../data')\n",
    "    IMAGE_DIR = Path('../img')\n",
    "\n",
    "# finally, check if we found the right pathes\n",
    "if os.path.isdir(DATA_DIR):\n",
    "    print(f'DATA_DIR is a directory, its path is {DATA_DIR}')\n",
    "else:\n",
    "    print(\"ERROR : DATA_DIR is not a directory\")\n",
    "\n",
    "if os.path.isdir(IMAGE_DIR):\n",
    "    print(f'IMAGE_DIR is a directory, its path is {IMAGE_DIR}')\n",
    "else:\n",
    "    print(\"ERROR : IMAGE_DIR is not a directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving working example able to inspire you to build your own AI project\n",
    "\n",
    "Hugging Face made available all-in-one ***pipelines*** including all the main steps of NLP.\n",
    "https://huggingface.co/course/chapter2/2?fw=pt\n",
    "* choosing a pre-trained model\n",
    "* adapting the input text into this model (tokenization, vectorization) \n",
    "* running the model on the transformed input data\n",
    "* adapting the model answer to human beings (ex : de-tokenization, to get an output text from an output vector or numbers)\n",
    "\n",
    "Once the pipeline works, you can decide to tune it, more and more, little by little, as one would do to transform their car for a speed race.\n",
    "So, you can decide to :\n",
    "* fine tune the model or train it from scratch (instead of using pre-trained model)\n",
    "* using a tokenizer from your own (instead of the default one)\n",
    "* clean the training data before feeding the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Example of question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is John and I work at unpackAI in Beijing.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_answer.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Example of Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [ \"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_answer = Classifier (sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_answer.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Example of Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to utilize NLP\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. Example of Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition (NER) is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Examples could be entities such as person (PER), organization (ORG), date (DATE), location (LOC), or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = pipeline(\"ner\", grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline(\"My name is John and I work at unpackAI in Beijing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
