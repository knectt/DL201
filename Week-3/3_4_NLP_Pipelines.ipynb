{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ðŸ’» UnpackAI DL201 Bootcamp - Week 3 - NLP pipelines\n\n### ðŸ“• Learning Objectives\n\n* Getting working examples able to achieve the main NLP tasks\n* Knowing the existence of Hugging Face and the strenth of its pre-trained models and all-in-one pipelines\n\n### ðŸ“– Concepts map\n\n* Pipeline","metadata":{}},{"cell_type":"code","source":"# import (use not verbose mode : ex \"import -Uqq pandas as pd\" if you are sure that there is no dependency error)\n\nfrom transformers import pipeline\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-06-03T17:11:28.099764Z","iopub.execute_input":"2022-06-03T17:11:28.100452Z","iopub.status.idle":"2022-06-03T17:11:28.104347Z","shell.execute_reply.started":"2022-06-03T17:11:28.100415Z","shell.execute_reply":"2022-06-03T17:11:28.103387Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"# Part 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"Giving working example able to inspire you to build your own AI project\n\nHugging Face made available all-in-one ***pipelines*** including all the main steps of NLP.\nhttps://huggingface.co/course/chapter2/2?fw=pt\n* choosing a pre-trained model\n* adapting the input text into this model (tokenization, vectorization) \n* running the model on the transformed input data\n* adapting the model answer to human beings (ex : de-tokenization, to get an output text from an output vector or numbers)\n\nOnce the pipeline works, you can decide to tune it, more and more, little by little, as one would do to transform their car for a speed race.\nSo, you can decide to :\n* fine tune the model or train it from scratch (instead of using pre-trained model)\n* using a tokenizer from your own (instead of the default one)\n* clean the training data before feeding the model\n","metadata":{}},{"cell_type":"markdown","source":"# Part 2. Example of question answering","metadata":{}},{"cell_type":"code","source":"question_answerer = pipeline(\"question-answering\")","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:52:21.040605Z","iopub.execute_input":"2022-06-03T16:52:21.041081Z","iopub.status.idle":"2022-06-03T16:52:35.334812Z","shell.execute_reply.started":"2022-06-03T16:52:21.041043Z","shell.execute_reply":"2022-06-03T16:52:35.333831Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n","output_type":"stream"}]},{"cell_type":"code","source":"my_answer = question_answerer(\n    question=\"Where do I work?\",\n    context=\"My name is John and I work at unpackAI in Beijing.\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:52:38.109713Z","iopub.execute_input":"2022-06-03T16:52:38.110149Z","iopub.status.idle":"2022-06-03T16:52:38.164679Z","shell.execute_reply.started":"2022-06-03T16:52:38.110114Z","shell.execute_reply":"2022-06-03T16:52:38.163880Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"my_answer","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:52:44.552559Z","iopub.execute_input":"2022-06-03T16:52:44.553205Z","iopub.status.idle":"2022-06-03T16:52:44.558786Z","shell.execute_reply.started":"2022-06-03T16:52:44.553162Z","shell.execute_reply":"2022-06-03T16:52:44.557907Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'score': 0.5068178772926331, 'start': 30, 'end': 38, 'answer': 'unpackAI'}"},"metadata":{}}]},{"cell_type":"code","source":"my_answer['answer']","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:52:47.000623Z","iopub.execute_input":"2022-06-03T16:52:47.001040Z","iopub.status.idle":"2022-06-03T16:52:47.007244Z","shell.execute_reply.started":"2022-06-03T16:52:47.001006Z","shell.execute_reply":"2022-06-03T16:52:47.006271Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'unpackAI'"},"metadata":{}}]},{"cell_type":"code","source":"def my_question_answerer(my_question, my_context):\n        \n    complete_answer = question_answerer(\n        question=my_question,\n        context=my_context\n    )\n    return complete_answer['answer']","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:52:49.680709Z","iopub.execute_input":"2022-06-03T16:52:49.681121Z","iopub.status.idle":"2022-06-03T16:52:49.686981Z","shell.execute_reply.started":"2022-06-03T16:52:49.681088Z","shell.execute_reply":"2022-06-03T16:52:49.685948Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"context = 'My name is James and I work in Shenzhen'\nquestion = 'Where do you work?'","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:52:51.714874Z","iopub.execute_input":"2022-06-03T16:52:51.715593Z","iopub.status.idle":"2022-06-03T16:52:51.719391Z","shell.execute_reply.started":"2022-06-03T16:52:51.715559Z","shell.execute_reply":"2022-06-03T16:52:51.718620Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"my_question_answerer(question,context)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:52:52.081812Z","iopub.execute_input":"2022-06-03T16:52:52.082473Z","iopub.status.idle":"2022-06-03T16:52:52.126370Z","shell.execute_reply.started":"2022-06-03T16:52:52.082438Z","shell.execute_reply":"2022-06-03T16:52:52.125612Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'Shenzhen'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Part 3. Example of Sentiment Analysis","metadata":{}},{"cell_type":"markdown","source":"Here, let's apply our pipeline on a list series (i.e. one column of a dataframe) containing text data.","metadata":{}},{"cell_type":"code","source":"Text_series = pd.Series([ \"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much!\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:54:01.937897Z","iopub.execute_input":"2022-06-03T16:54:01.938916Z","iopub.status.idle":"2022-06-03T16:54:01.944432Z","shell.execute_reply.started":"2022-06-03T16:54:01.938874Z","shell.execute_reply":"2022-06-03T16:54:01.943376Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"Text_series.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:54:02.276663Z","iopub.execute_input":"2022-06-03T16:54:02.277416Z","iopub.status.idle":"2022-06-03T16:54:02.284014Z","shell.execute_reply.started":"2022-06-03T16:54:02.277370Z","shell.execute_reply":"2022-06-03T16:54:02.283177Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(2,)"},"metadata":{}}]},{"cell_type":"markdown","source":"Now, we have to transform this series into a normal list, because pipelines can deal with list but not series.","metadata":{}},{"cell_type":"code","source":"Text_list = Text_series.to_list()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:54:17.905486Z","iopub.execute_input":"2022-06-03T16:54:17.908117Z","iopub.status.idle":"2022-06-03T16:54:17.912336Z","shell.execute_reply.started":"2022-06-03T16:54:17.908071Z","shell.execute_reply":"2022-06-03T16:54:17.911468Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"len(Text_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:54:31.713169Z","iopub.execute_input":"2022-06-03T16:54:31.713635Z","iopub.status.idle":"2022-06-03T16:54:31.719688Z","shell.execute_reply.started":"2022-06-03T16:54:31.713601Z","shell.execute_reply":"2022-06-03T16:54:31.718923Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"markdown","source":"We load the sentiment analysis pipeline","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:54:51.744314Z","iopub.execute_input":"2022-06-03T16:54:51.745007Z","iopub.status.idle":"2022-06-03T16:54:51.750307Z","shell.execute_reply.started":"2022-06-03T16:54:51.744960Z","shell.execute_reply":"2022-06-03T16:54:51.749095Z"}}},{"cell_type":"code","source":"classifier = pipeline(\"sentiment-analysis\")","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:55:02.220388Z","iopub.execute_input":"2022-06-03T16:55:02.221494Z","iopub.status.idle":"2022-06-03T16:55:15.736362Z","shell.execute_reply.started":"2022-06-03T16:55:02.221444Z","shell.execute_reply":"2022-06-03T16:55:15.735309Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n","output_type":"stream"}]},{"cell_type":"code","source":"list_of_answers = classifier (Text_list)\nlist_of_answers","metadata":{"execution":{"iopub.status.busy":"2022-06-03T17:07:32.917489Z","iopub.execute_input":"2022-06-03T17:07:32.917940Z","iopub.status.idle":"2022-06-03T17:07:32.993369Z","shell.execute_reply.started":"2022-06-03T17:07:32.917904Z","shell.execute_reply":"2022-06-03T17:07:32.992437Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"},"metadata":{}}]},{"cell_type":"code","source":"len(list_of_answers)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T16:56:20.855832Z","iopub.execute_input":"2022-06-03T16:56:20.856258Z","iopub.status.idle":"2022-06-03T16:56:20.862359Z","shell.execute_reply.started":"2022-06-03T16:56:20.856223Z","shell.execute_reply":"2022-06-03T16:56:20.861600Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's try to get the list of labels, or the list of score","metadata":{}},{"cell_type":"code","source":"#list_of_answers[:]['label'] # error","metadata":{"execution":{"iopub.status.busy":"2022-06-03T17:01:52.863582Z","iopub.execute_input":"2022-06-03T17:01:52.864521Z","iopub.status.idle":"2022-06-03T17:01:52.869194Z","shell.execute_reply.started":"2022-06-03T17:01:52.864474Z","shell.execute_reply":"2022-06-03T17:01:52.867901Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"So, to get them, we have to transform it back to a series","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_of_answers = pd.Series(list_of_answers)\nseries_of_answers.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T17:00:22.488753Z","iopub.execute_input":"2022-06-03T17:00:22.489213Z","iopub.status.idle":"2022-06-03T17:00:22.498814Z","shell.execute_reply.started":"2022-06-03T17:00:22.489178Z","shell.execute_reply":"2022-06-03T17:00:22.497079Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"(2,)"},"metadata":{}}]},{"cell_type":"code","source":"series_of_labels = series_of_answers.apply(lambda x: x['label'])\nseries_of_labels","metadata":{"execution":{"iopub.status.busy":"2022-06-03T17:07:50.565756Z","iopub.execute_input":"2022-06-03T17:07:50.566335Z","iopub.status.idle":"2022-06-03T17:07:50.573746Z","shell.execute_reply.started":"2022-06-03T17:07:50.566301Z","shell.execute_reply":"2022-06-03T17:07:50.572852Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"0    POSITIVE\n1    NEGATIVE\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"series_of_scores = series_of_answers.apply(lambda x: x['score'])\nseries_of_scores","metadata":{"execution":{"iopub.status.busy":"2022-06-03T17:08:29.254609Z","iopub.execute_input":"2022-06-03T17:08:29.255646Z","iopub.status.idle":"2022-06-03T17:08:29.265007Z","shell.execute_reply.started":"2022-06-03T17:08:29.255598Z","shell.execute_reply":"2022-06-03T17:08:29.263727Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"0    0.959805\n1    0.999456\ndtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"Here, we remark than we cannot tell if it is positive or not by reading the score.\nSo, we have to combine both the score and the label to get a signed score.","metadata":{}},{"cell_type":"code","source":"series_of_signed_scores = np.where(series_of_labels == 'POSITIVE', series_of_scores, -1 * series_of_scores)\nseries_of_signed_scores","metadata":{"execution":{"iopub.status.busy":"2022-06-03T17:25:20.776157Z","iopub.execute_input":"2022-06-03T17:25:20.776547Z","iopub.status.idle":"2022-06-03T17:25:20.784645Z","shell.execute_reply.started":"2022-06-03T17:25:20.776517Z","shell.execute_reply":"2022-06-03T17:25:20.783999Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"array([ 0.95980495, -0.99945587])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Part 4. Example of Text Generation","metadata":{}},{"cell_type":"code","source":"generator = pipeline(\"text-generation\")","metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:35:00.85946Z","iopub.status.busy":"2022-05-29T08:35:00.858816Z","iopub.status.idle":"2022-05-29T08:35:38.364742Z","shell.execute_reply":"2022-05-29T08:35:38.36358Z","shell.execute_reply.started":"2022-05-29T08:35:00.859429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator(\n    \"In this course, we will teach you how to utilize NLP\",\n    max_length=30,\n    num_return_sequences=2\n)","metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:39:01.419258Z","iopub.status.busy":"2022-05-29T08:39:01.418678Z","iopub.status.idle":"2022-05-29T08:39:03.868734Z","shell.execute_reply":"2022-05-29T08:39:03.867985Z","shell.execute_reply.started":"2022-05-29T08:39:01.419203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 5. Example of Named Entity Recognition (NER)","metadata":{}},{"cell_type":"markdown","source":"Named Entity Recognition (NER) is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Examples could be entities such as person (PER), organization (ORG), date (DATE), location (LOC), or more.","metadata":{}},{"cell_type":"code","source":"ner_pipeline = pipeline(\"ner\", grouped_entities=True)","metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:39:15.78028Z","iopub.status.busy":"2022-05-29T08:39:15.77704Z","iopub.status.idle":"2022-05-29T08:40:25.157Z","shell.execute_reply":"2022-05-29T08:40:25.156001Z","shell.execute_reply.started":"2022-05-29T08:39:15.780236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ner_pipeline(\"My name is John and I work at unpackAI in Beijing.\")","metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:40:37.6511Z","iopub.status.busy":"2022-05-29T08:40:37.650219Z","iopub.status.idle":"2022-05-29T08:40:37.976582Z","shell.execute_reply":"2022-05-29T08:40:37.975602Z","shell.execute_reply.started":"2022-05-29T08:40:37.651062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 6. How to fine tune a transformer ?","metadata":{}},{"cell_type":"markdown","source":"Finetuning a transformer is not hard, but transformers were made to work with shared data, and shared data must respect some strict rules to adapt different models. So, a new data type was invented : the ***Dataset***\n\nAnd the main difficulty of transformers fine tuning, is to transform our training data into a Dataset.\n\nYou may see an example here :\nhttps://www.kaggle.com/code/philanoe/intent-classifier-training","metadata":{}}]}