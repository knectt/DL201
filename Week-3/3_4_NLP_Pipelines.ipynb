{"cells":[{"cell_type":"markdown","metadata":{},"source":["## ðŸ’» UnpackAI DL201 Bootcamp - Week 3 - NLP pipelines\n","\n","### ðŸ“• Learning Objectives\n","\n","* Getting working examples able to achieve the main NLP tasks\n","* Knowing the existence of Hugging Face and the strenth of its pre-trained models and all-in-one pipelines\n","\n","### ðŸ“– Concepts map\n","\n","* Pipeline"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:11:31.089945Z","iopub.status.busy":"2022-05-29T08:11:31.089404Z","iopub.status.idle":"2022-05-29T08:11:31.094187Z","shell.execute_reply":"2022-05-29T08:11:31.093131Z","shell.execute_reply.started":"2022-05-29T08:11:31.089915Z"},"trusted":true},"outputs":[],"source":["# import (use not verbose mode : ex \"import -Uqq pandas as pd\" if you are sure that there is no dependency error)\n","\n","from transformers import pipeline\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["# Part 1. Introduction"]},{"cell_type":"markdown","metadata":{},"source":["Giving working example able to inspire you to build your own AI project\n","\n","Hugging Face made available all-in-one ***pipelines*** including all the main steps of NLP.\n","https://huggingface.co/course/chapter2/2?fw=pt\n","* choosing a pre-trained model\n","* adapting the input text into this model (tokenization, vectorization) \n","* running the model on the transformed input data\n","* adapting the model answer to human beings (ex : de-tokenization, to get an output text from an output vector or numbers)\n","\n","Once the pipeline works, you can decide to tune it, more and more, little by little, as one would do to transform their car for a speed race.\n","So, you can decide to :\n","* fine tune the model or train it from scratch (instead of using pre-trained model)\n","* using a tokenizer from your own (instead of the default one)\n","* clean the training data before feeding the model\n"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2. Example of question answering"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:12:08.580348Z","iopub.status.busy":"2022-05-29T08:12:08.579914Z","iopub.status.idle":"2022-05-29T08:12:32.426313Z","shell.execute_reply":"2022-05-29T08:12:32.425598Z","shell.execute_reply.started":"2022-05-29T08:12:08.580311Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n","Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 473/473 [00:00<00:00, 805kB/s]\n","Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 249M/249M [01:56<00:00, 2.23MB/s] \n","Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.0/29.0 [00:00<00:00, 23.1kB/s]\n","Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208k/208k [00:04<00:00, 45.9kB/s] \n","Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 426k/426k [00:02<00:00, 209kB/s]  \n"]}],"source":["question_answerer = pipeline(\"question-answering\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:13:02.458152Z","iopub.status.busy":"2022-05-29T08:13:02.457136Z","iopub.status.idle":"2022-05-29T08:13:02.524038Z","shell.execute_reply":"2022-05-29T08:13:02.523114Z","shell.execute_reply.started":"2022-05-29T08:13:02.458108Z"},"trusted":true},"outputs":[],"source":["my_answer = question_answerer(\n","    question=\"Where do I work?\",\n","    context=\"My name is John and I work at unpackAI in Beijing.\"\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:13:31.426853Z","iopub.status.busy":"2022-05-29T08:13:31.426120Z","iopub.status.idle":"2022-05-29T08:13:31.432543Z","shell.execute_reply":"2022-05-29T08:13:31.431584Z","shell.execute_reply.started":"2022-05-29T08:13:31.426811Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'score': 0.5068178772926331, 'start': 30, 'end': 38, 'answer': 'unpackAI'}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["my_answer"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello\n"]}],"source":["print('Hello')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:13:18.256585Z","iopub.status.busy":"2022-05-29T08:13:18.256010Z","iopub.status.idle":"2022-05-29T08:13:18.261207Z","shell.execute_reply":"2022-05-29T08:13:18.260568Z","shell.execute_reply.started":"2022-05-29T08:13:18.256507Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'unpackAI'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["my_answer['answer']"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:17:00.505186Z","iopub.status.busy":"2022-05-29T08:17:00.504723Z","iopub.status.idle":"2022-05-29T08:17:00.510573Z","shell.execute_reply":"2022-05-29T08:17:00.509613Z","shell.execute_reply.started":"2022-05-29T08:17:00.505150Z"},"trusted":true},"outputs":[],"source":["def my_question_answerer(my_question,my_context):\n","    \n","    \n","    complete_answer = question_answerer(\n","        question=my_question,\n","        context=my_context\n","    )\n","    return complete_answer['answer']"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["context = 'My name is James and I work in Shenzhen'\n","question = 'Where do you work?'"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:17:30.380617Z","iopub.status.busy":"2022-05-29T08:17:30.380190Z","iopub.status.idle":"2022-05-29T08:17:30.429547Z","shell.execute_reply":"2022-05-29T08:17:30.428544Z","shell.execute_reply.started":"2022-05-29T08:17:30.380580Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Shenzhen'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["my_question_answerer(question,context)"]},{"cell_type":"markdown","metadata":{},"source":["# Part 3. Example of Sentiment Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:24:07.969348Z","iopub.status.busy":"2022-05-29T08:24:07.968943Z","iopub.status.idle":"2022-05-29T08:24:30.124737Z","shell.execute_reply":"2022-05-29T08:24:30.123452Z","shell.execute_reply.started":"2022-05-29T08:24:07.969318Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"]}],"source":["classifier = pipeline(\"sentiment-analysis\")"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["def sentiment_analysis_pipeline(text):\n","    \"\"\"_summary_\n","    Takes a column of strings, cuts it down to the first 512 characters\n","    allowed by the model, then outputs a sentiment\n","    \n","    Args:\n","        text (_type_): _description_\n","        Text, usually from a pandas dataframe\n","        if it is more than 512 characters long, then it\n","        won't fit into the tokenizer\n","\n","    Returns:\n","        _type_: _description_\n","        returns a value between -1 and 1\n","        negative numbers signify that it is negative\n","        and positive numbers signify a positive review\n","        \n","        The closer it is to 1 or -1 signifies the confidence that it\n","        is a negative review\n","    \"\"\"\n","    token_length_limit = 512\n","    output = classifier(text[0:token_length_limit -1 ])[0]\n","    if output['label'] == 'NEGATIVE':\n","        output['score'] = output['score'] * -1 \n","    return output['score']\n","    "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:33:36.076459Z","iopub.status.busy":"2022-05-29T08:33:36.076065Z","iopub.status.idle":"2022-05-29T08:33:36.081478Z","shell.execute_reply":"2022-05-29T08:33:36.080697Z","shell.execute_reply.started":"2022-05-29T08:33:36.076428Z"},"trusted":true},"outputs":[],"source":["sentence_list = [ \"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much!\"]"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:33:58.613898Z","iopub.status.busy":"2022-05-29T08:33:58.613492Z","iopub.status.idle":"2022-05-29T08:33:58.687933Z","shell.execute_reply":"2022-05-29T08:33:58.687154Z","shell.execute_reply.started":"2022-05-29T08:33:58.613859Z"},"trusted":true},"outputs":[],"source":["my_answer = classifier (sentence_list)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:34:15.350773Z","iopub.status.busy":"2022-05-29T08:34:15.350182Z","iopub.status.idle":"2022-05-29T08:34:15.357417Z","shell.execute_reply":"2022-05-29T08:34:15.356570Z","shell.execute_reply.started":"2022-05-29T08:34:15.350722Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'label': 'POSITIVE', 'score': 0.9598047137260437}"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["my_answer[0]"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:34:45.693756Z","iopub.status.busy":"2022-05-29T08:34:45.693312Z","iopub.status.idle":"2022-05-29T08:34:45.699789Z","shell.execute_reply":"2022-05-29T08:34:45.698416Z","shell.execute_reply.started":"2022-05-29T08:34:45.693721Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["POSITIVE\n","NEGATIVE\n"]}],"source":["for items in my_answer:\n","    print(items['label'])"]},{"cell_type":"markdown","metadata":{},"source":["# Part 4. Example of Text Generation"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:35:00.859460Z","iopub.status.busy":"2022-05-29T08:35:00.858816Z","iopub.status.idle":"2022-05-29T08:35:38.364742Z","shell.execute_reply":"2022-05-29T08:35:38.363580Z","shell.execute_reply.started":"2022-05-29T08:35:00.859429Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n"]}],"source":["generator = pipeline(\"text-generation\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:39:01.419258Z","iopub.status.busy":"2022-05-29T08:39:01.418678Z","iopub.status.idle":"2022-05-29T08:39:03.868734Z","shell.execute_reply":"2022-05-29T08:39:03.867985Z","shell.execute_reply.started":"2022-05-29T08:39:01.419203Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"data":{"text/plain":["[{'generated_text': 'In this course, we will teach you how to utilize NLP in NLP programming. In this course, you will learn how to use NLP'},\n"," {'generated_text': 'In this course, we will teach you how to utilize NLP or even NAP on a real project rather than using an in-house NLP'}]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["generator(\n","    \"In this course, we will teach you how to utilize NLP\",\n","    max_length=30,\n","    num_return_sequences=2\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Part 5. Example of Named Entity Recognition (NER)"]},{"cell_type":"markdown","metadata":{},"source":["Named Entity Recognition (NER) is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Examples could be entities such as person (PER), organization (ORG), date (DATE), location (LOC), or more."]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:39:15.780280Z","iopub.status.busy":"2022-05-29T08:39:15.777040Z","iopub.status.idle":"2022-05-29T08:40:25.157000Z","shell.execute_reply":"2022-05-29T08:40:25.156001Z","shell.execute_reply.started":"2022-05-29T08:39:15.780236Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n","/home/jentlejames/anaconda3/envs/unpackAIdev/lib/python3.8/site-packages/transformers/pipelines/token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n","  warnings.warn(\n"]}],"source":["ner_pipeline = pipeline(\"ner\", grouped_entities=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-05-29T08:40:37.651100Z","iopub.status.busy":"2022-05-29T08:40:37.650219Z","iopub.status.idle":"2022-05-29T08:40:37.976582Z","shell.execute_reply":"2022-05-29T08:40:37.975602Z","shell.execute_reply.started":"2022-05-29T08:40:37.651062Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'entity_group': 'PER',\n","  'score': 0.9986534,\n","  'word': 'John',\n","  'start': 11,\n","  'end': 15},\n"," {'entity_group': 'ORG',\n","  'score': 0.7754366,\n","  'word': 'unpackAI',\n","  'start': 30,\n","  'end': 38},\n"," {'entity_group': 'LOC',\n","  'score': 0.99954224,\n","  'word': 'Beijing',\n","  'start': 42,\n","  'end': 49}]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["ner_pipeline(\"My name is John and I work at unpackAI in Beijing.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":4}
