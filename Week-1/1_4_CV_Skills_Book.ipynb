{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ’» UnpackAI DL201 Bootcamp - Week 1 - Skills: Computer Vision\n\n## ðŸ“• Learning Objectives\n\n* Loading data\n* Unzipping data\n* Retrieving label information\n* AI model training and results analysis on Computer Vision","metadata":{"papermill":{"duration":0.042429,"end_time":"2022-05-20T17:31:48.782048","exception":false,"start_time":"2022-05-20T17:31:48.739619","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"# Part 0 : Code preparation","metadata":{"papermill":{"duration":0.03789,"end_time":"2022-05-20T17:31:48.860031","exception":false,"start_time":"2022-05-20T17:31:48.822141","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2 \nimport torch as t\nfrom matplotlib import pyplot as plt\nfrom pathlib import Path\nimport os\nfrom shutil import unpack_archive\nfrom PIL import Image\nfrom IPython.display import display\n\n# import data and images if necessary, and choose the right path\nis_kaggle = True   # True if you are on Kaggle, False for local Windows, Linux or Mac environments.\n\nif is_kaggle:\n    !pip install openpyxl\n    !git clone https://github.com/unpackAI/DL201.git\n    IMAGE_DIR = Path('/kaggle/working/DL201/img')\n    DATA_DIR = Path('/kaggle/working/DL201/data')\n\nelse:\n\n    # This section is for local execution, it is assumed that the notebook is on the 'Week-1' folder\n    # of the DL201 repository.\n    current_dir = os.getcwd()\n    os.chdir(\"..\")\n    DATA_DIR = os.path.join(os.getcwd(), \"data\")\n    IMAGE_DIR = os.path.join(os.getcwd(), \"img\")    \n\n\n# finally, check if we found the right pathes\nif os.path.isdir(DATA_DIR):\n    print(f'DATA_DIR is a directory, its path is {DATA_DIR}')\nelse:\n    print(\"ERROR : DATA_DIR is not a directory\")\n\nif os.path.isdir(IMAGE_DIR):\n    print(f'IMAGE_DIR is a directory, its path is {IMAGE_DIR}')\nelse:\n    print(\"ERROR : IMAGE_DIR is not a directory\")","metadata":{"papermill":{"duration":21.034916,"end_time":"2022-05-20T17:32:09.932241","exception":false,"start_time":"2022-05-20T17:31:48.897325","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 1: Loading the data\n<hr style=\"border:4px solid gray\"> </hr>","metadata":{"papermill":{"duration":0.050022,"end_time":"2022-05-20T17:32:10.035657","exception":false,"start_time":"2022-05-20T17:32:09.985635","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"As always, the question becomes, how do we access our data.","metadata":{"papermill":{"duration":0.050626,"end_time":"2022-05-20T17:32:10.136514","exception":false,"start_time":"2022-05-20T17:32:10.085888","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"## 1.1 How Large is the dataset?\n\nBefore downloading the data, it is a good idea to know how large the dataset is because this will affect how you move forward. If it is very large, you may need to consider if you can download it or not, how much time this would take, how it will be stored in your computer, etc.\n\nYou may need to select a sample out of the dataset to work with rather than work with the whole set. This will speed up exploring the data because you won't constantly be waiting for the computer to process the data.\n\nThis information is usually found online, in the Readme following the data or displayed by your computer when you start downloading.","metadata":{"papermill":{"duration":0.049704,"end_time":"2022-05-20T17:32:10.236456","exception":false,"start_time":"2022-05-20T17:32:10.186752","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"## 1.2 Working with compressed files?","metadata":{"papermill":{"duration":0.049813,"end_time":"2022-05-20T17:32:10.336936","exception":false,"start_time":"2022-05-20T17:32:10.287123","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"***Zip*** files are incredibly common in many areas.\n\nFor datasets, they serve two primary purposes:\n\n1. This format bundles together many files into one and makes it easier and faster to send it over the internet. Network protocols are similar to the mail. It's much less complicated to send a shipping container rather than do paperwork and handling of thousands of individual boxes.\n\n2. Compression. The other problem is bandwidth. Zip files, along with other formats, can make files smaller which is beneficial because they take up less space on the hard drive. More importantly, this means that we can download the dataset faster. ","metadata":{"papermill":{"duration":0.049371,"end_time":"2022-05-20T17:32:10.436529","exception":false,"start_time":"2022-05-20T17:32:10.387158","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[],"toc-hr-collapsed":true}},{"cell_type":"markdown","source":"### Step 1: Find the exact file path","metadata":{"papermill":{"duration":0.049458,"end_time":"2022-05-20T17:32:10.536024","exception":false,"start_time":"2022-05-20T17:32:10.486566","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"# Setting the file path using pathlib\nemotionsImagesZipPath = os.path.join(DATA_DIR, 'CV', 'Emotions_Images_Sample.zip')\nos.path.isfile(emotionsImagesZipPath)","metadata":{"papermill":{"duration":0.061585,"end_time":"2022-05-20T17:32:10.648266","exception":false,"start_time":"2022-05-20T17:32:10.586681","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Unzip the files\n\nIn this code, we are using a library called ***shutil***\nShutil is short for shell utility.\n\nThis allows python to make commands in the shell.\n\nIn this case, we are telling it to unzip a file X and put it in Y directory.\nX is a file path while Y is a directory path.","metadata":{"papermill":{"duration":0.049878,"end_time":"2022-05-20T17:32:10.748831","exception":false,"start_time":"2022-05-20T17:32:10.698953","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"Output_Directory = os.path.join(DATA_DIR,'OutputDirectory')\n\nif not os.path.isdir(Output_Directory): #this allows us to run the cell several times\n    os.mkdir(Output_Directory)\n    unpack_archive(emotionsImagesZipPath, Output_Directory)","metadata":{"papermill":{"duration":0.103862,"end_time":"2022-05-20T17:32:10.905146","exception":false,"start_time":"2022-05-20T17:32:10.801284","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Check the file path\n\nNow that we extracted the data, we now need to make sure that we know where our data is, and check up on it before proceeding to the next level.\n\nCheck the output of the next command and see what it is doing.","metadata":{"papermill":{"duration":0.051331,"end_time":"2022-05-20T17:32:11.007986","exception":false,"start_time":"2022-05-20T17:32:10.956655","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"os.listdir(Output_Directory)","metadata":{"papermill":{"duration":0.058273,"end_time":"2022-05-20T17:32:11.117656","exception":false,"start_time":"2022-05-20T17:32:11.059383","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EMOTIONS_IMAGES_DIR = os.path.join(Output_Directory,'Emotions_Images_Sample')\nlabels = os.listdir(EMOTIONS_IMAGES_DIR)\nprint(labels)","metadata":{"papermill":{"duration":0.059197,"end_time":"2022-05-20T17:32:11.227567","exception":false,"start_time":"2022-05-20T17:32:11.168370","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we see a list of labels as directory names. Let's remind the different ways to connect the pictures and their metadata such as labels.\n\n## 1.3 Ways of storing the data and metadata\n\nMany computer vision data sets are organized in three ways.\n\n<dt>File trees</dt>\n<df>The picture files are grouped by meaningfull directories. We may find their label and other information about them with the directory they belong to. Finding them is done by exploring what is called a ***file tree***</df>\n\n<dt>Metadata</dt>\n<df>The picture files are not well separated in the file tree, or might even be stored on different repositories on the web. To retrieve them and the corresponding labels, we have a Metadata file (can be a JSON or CSV file) containing the file list, file paths and other information like the labels</df>\n\n<dt>File names</dt>\n<df>As we saw in the PETS dataset, where cats were lowercases and dogs were uppercases file names, some pictures of some datasets contain their label inside the filename itself</df>","metadata":{"papermill":{"duration":0.050629,"end_time":"2022-05-20T17:32:11.331298","exception":false,"start_time":"2022-05-20T17:32:11.280669","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"## 1.4 Class analysis from file tree\nHere, the labels are conveniently stored as directory names, so they are easy to extract.","metadata":{"papermill":{"duration":0.050334,"end_time":"2022-05-20T17:32:11.432600","exception":false,"start_time":"2022-05-20T17:32:11.382266","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"print(f'total number of labels: {len(labels)}')","metadata":{"papermill":{"duration":0.058888,"end_time":"2022-05-20T17:32:11.542026","exception":false,"start_time":"2022-05-20T17:32:11.483138","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"instancesPerClassDict = {}\n\nfilepathDictionary = {}\n\nfor label in os.listdir(EMOTIONS_IMAGES_DIR):\n    \n    # This gives us a label for each bit of code\n    imagesDirectory = os.path.join(EMOTIONS_IMAGES_DIR,label)\n    \n    # This code gives a list of all the images in the directory\n    \n    images = os.listdir(imagesDirectory)\n    for fileName in images:\n        \n        imagePath = os.path.join(imagesDirectory,fileName) # makes a longer path\n        # use imagePath to do something\n            \n    instancesPerClassDict[label] = len(images)\n    \nfor key, value in instancesPerClassDict.items():\n    print(f'Class: ({key}) contains {value} instances')\n","metadata":{"papermill":{"duration":0.062924,"end_time":"2022-05-20T17:32:11.657082","exception":false,"start_time":"2022-05-20T17:32:11.594158","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we have our data in a format that it can be put into a fastAI model to give us more information.","metadata":{"papermill":{"duration":0.051443,"end_time":"2022-05-20T17:32:11.760267","exception":false,"start_time":"2022-05-20T17:32:11.708824","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"## 1.5 Class analysis from Metadata File","metadata":{"papermill":{"duration":0.066784,"end_time":"2022-05-20T17:32:11.887976","exception":false,"start_time":"2022-05-20T17:32:11.821192","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"In some cases, the files may be located on a cloud server, or put together into one large directory. This means that the information is not organized with a file tree, but rather in metadata.\n\nThis metadata can come as a CSV or a JSON File.","metadata":{"papermill":{"duration":0.050958,"end_time":"2022-05-20T17:32:11.990643","exception":false,"start_time":"2022-05-20T17:32:11.939685","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"Here, we work with the google landmarks image dataset, it contains lots of information on different photos that users have uploaded along with different kinds of metadata.\n\nHowever, the  dataset is quite large, so it makes more sense to have an individual metadata files. It can allows us to donwload only the pictures we want.\n\nThese metadata files contain both the labels and the file paths that we need.\n\n***Identifying the x and the y***\nThe features (x) in this case are the images ; labels (y) in this case are the landmark IDs.","metadata":{"papermill":{"duration":0.052553,"end_time":"2022-05-20T17:32:12.094779","exception":false,"start_time":"2022-05-20T17:32:12.042226","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"# Load 3 sample images from the Google Ladmark dataset\nimage_path_1 = os.path.join(IMAGE_DIR, \"week1\", \"IMG_1071.JPG\")\nimage_path_2 = os.path.join(IMAGE_DIR, \"week1\", \"IMG_2053p.jpg\")\nimage_path_3 = os.path.join(IMAGE_DIR, \"week1\", \"IMG_20130605_142805.jpg\")\nimage_object_1 = Image.open(image_path_1)\nimage_object_2 = Image.open(image_path_2) \nimage_object_3 = Image.open(image_path_3)  ","metadata":{"papermill":{"duration":0.828301,"end_time":"2022-05-20T17:32:12.974724","exception":false,"start_time":"2022-05-20T17:32:12.146423","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resize the image to 25% of its original size\nimage_object_1 = image_object_1.resize((int(image_object_1.width/4), int(image_object_1.height/4)))\nimage_object_2 = image_object_2.resize((int(image_object_2.width/4), int(image_object_2.height/4)))\nimage_object_3 = image_object_3.resize((int(image_object_3.width/4), int(image_object_3.height/4)))","metadata":{"papermill":{"duration":1.078187,"end_time":"2022-05-20T17:32:14.185921","exception":false,"start_time":"2022-05-20T17:32:13.107734","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the images (Run this cell)\ndisplay(image_object_1)\ndisplay(image_object_2)\ndisplay(image_object_3)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Examples of the Landmarks dataset: The link for the images is contained on the metadata file.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"googleLandmarksPath = os.path.join(DATA_DIR,'CV','landmarks')\nos.path.isdir(googleLandmarksPath)","metadata":{"papermill":{"duration":0.357217,"end_time":"2022-05-20T17:32:16.230457","exception":false,"start_time":"2022-05-20T17:32:15.873240","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List the CSV files from the Google Landmarks dataset folder\nlandmarks_csv_data = dict()\ncsv_filenames = os.listdir(googleLandmarksPath)\nprint(f\"CSV files on dataset folder: {csv_filenames}\")","metadata":{"papermill":{"duration":0.40831,"end_time":"2022-05-20T17:32:16.988089","exception":false,"start_time":"2022-05-20T17:32:16.579779","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the CSV files using a dictionary: the key is the file name and the value is a dataframe with the contents of the file\nfor csv_filename in csv_filenames:\n    csv_path = os.path.join(googleLandmarksPath, csv_filename)\n    landmarks_csv_data[csv_filename] = pd.read_csv(csv_path, delimiter=',')","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we loaded all the metadata files. We will look at their name to know what they represent, and check their shape to know rapidly the number of features and sample they describe. If the name of the file is not clear enough, we can sometimes get some information by observing the relationships between the shapes of two files.","metadata":{"papermill":{"duration":0.347482,"end_time":"2022-05-20T17:32:17.685453","exception":false,"start_time":"2022-05-20T17:32:17.337971","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"# Inspect the file \"train.csv\" as an example\nprint(f\"- Size of the 'train.csv' file: {landmarks_csv_data['train.csv'].shape}\")\nprint(landmarks_csv_data['train.csv'].head())","metadata":{"papermill":{"duration":0.367698,"end_time":"2022-05-20T17:32:18.401331","exception":false,"start_time":"2022-05-20T17:32:18.033633","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_csv_data['train.csv'].drop(['Unnamed: 0'],axis=1,inplace=True)\nprint(landmarks_csv_data['train.csv'].shape)\nlandmarks_csv_data['train.csv'].head()","metadata":{"papermill":{"duration":0.366325,"end_time":"2022-05-20T17:32:19.115033","exception":false,"start_time":"2022-05-20T17:32:18.748708","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this dataset, the label is the landmark ID\n\nThe file location is a little more tricky because it is stored on google's servers, and needs to be downloaded. ","metadata":{"papermill":{"duration":0.34791,"end_time":"2022-05-20T17:32:19.808682","exception":false,"start_time":"2022-05-20T17:32:19.460772","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"landmarkLabels = landmarks_csv_data['train.csv']['landmark_id']\nlandmarkURLs = landmarks_csv_data['train.csv']['url']","metadata":{"papermill":{"duration":0.360919,"end_time":"2022-05-20T17:32:20.557431","exception":false,"start_time":"2022-05-20T17:32:20.196512","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Although these are different, the principles remain the same as before : we need to know what the image is, and where the image is stored. The label and the file path/url will hold this information.\n\nYou can check another example here : https://www.kaggle.com/piyushrg/computer-vision-av-fastai/notebook","metadata":{"papermill":{"duration":0.349192,"end_time":"2022-05-20T17:32:21.254802","exception":false,"start_time":"2022-05-20T17:32:20.905610","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"## Part 2 : Loading the data into the dataloader\n<hr style=\"border:4px solid gray\"> </hr>\n","metadata":{"papermill":{"duration":0.348229,"end_time":"2022-05-20T17:32:21.950379","exception":false,"start_time":"2022-05-20T17:32:21.602150","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"In order to leverage a fastAI model, the two key pieces of information that we will need to fit the data into the model are the ***labels***, and how the images are stored. \n\nOnce we can do that, we can go ahead and train a ***preliminary model*** to get quantified information on how to build the final model.","metadata":{"papermill":{"duration":0.347869,"end_time":"2022-05-20T17:32:22.642821","exception":false,"start_time":"2022-05-20T17:32:22.294952","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"# Imports, this cell must be run twice because there are dependencies problems with the preloaded libraries of Kaggle\n!pip install -Uqq fastbook[full]\n\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nsetup_book()","metadata":{"papermill":{"duration":23.875391,"end_time":"2022-05-20T17:32:46.889019","exception":false,"start_time":"2022-05-20T17:32:23.013628","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the Data into FastAI Dataloader\n\nOnce we have the paths of each image, we can use a dataloader to preprocess and transform the data automatically for us using FastAI","metadata":{"papermill":{"duration":0.345603,"end_time":"2022-05-20T17:32:47.590902","exception":false,"start_time":"2022-05-20T17:32:47.245299","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"class DataLoaders(GetAttr):\n  def __init__(self, *loaders): self.loaders = loaders\n  def __getitem__(self, i): return self.loaders[i]\n  train,valid = add_props(lambda i, self: self[i])","metadata":{"papermill":{"duration":0.360288,"end_time":"2022-05-20T17:32:48.302478","exception":false,"start_time":"2022-05-20T17:32:47.942190","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=99),\n    get_y=parent_label,\n    item_tfms=Resize(225,225)\n    )","metadata":{"papermill":{"duration":0.375125,"end_time":"2022-05-20T17:32:49.023347","exception":false,"start_time":"2022-05-20T17:32:48.648222","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions = emotions.new(\n    item_tfms=RandomResizedCrop(28, min_scale=0.5),\n    batch_tfms=aug_transforms()\n)","metadata":{"papermill":{"duration":0.356728,"end_time":"2022-05-20T17:32:49.725526","exception":false,"start_time":"2022-05-20T17:32:49.368798","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls = emotions.dataloaders(EMOTIONS_IMAGES_DIR)","metadata":{"papermill":{"duration":0.462949,"end_time":"2022-05-20T17:32:50.535257","exception":false,"start_time":"2022-05-20T17:32:50.072308","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.valid.show_batch(max_n=16, nrows=4)","metadata":{"papermill":{"duration":1.034044,"end_time":"2022-05-20T17:32:51.913329","exception":false,"start_time":"2022-05-20T17:32:50.879285","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 3 : Training the Model","metadata":{"papermill":{"duration":0.35326,"end_time":"2022-05-20T17:32:52.618636","exception":false,"start_time":"2022-05-20T17:32:52.265376","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"learn = cnn_learner(dls, resnet34, metrics=error_rate)","metadata":{"papermill":{"duration":3.353906,"end_time":"2022-05-20T17:32:56.321263","exception":false,"start_time":"2022-05-20T17:32:52.967357","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.fine_tune(5)","metadata":{"papermill":{"duration":30.175193,"end_time":"2022-05-20T17:33:26.882980","exception":false,"start_time":"2022-05-20T17:32:56.707787","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 4: Interpreting the Results","metadata":{"papermill":{"duration":0.352403,"end_time":"2022-05-20T17:33:27.594798","exception":false,"start_time":"2022-05-20T17:33:27.242395","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)","metadata":{"papermill":{"duration":0.93774,"end_time":"2022-05-20T17:33:28.892466","exception":false,"start_time":"2022-05-20T17:33:27.954726","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What is the Accuracy of the Model?","metadata":{"papermill":{"duration":0.454862,"end_time":"2022-05-20T17:33:29.733637","exception":false,"start_time":"2022-05-20T17:33:29.278775","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"interp.print_classification_report()","metadata":{"papermill":{"duration":0.880616,"end_time":"2022-05-20T17:33:30.967944","exception":false,"start_time":"2022-05-20T17:33:30.087328","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What Does the Confusion Matrix Look Like?","metadata":{"papermill":{"duration":0.353041,"end_time":"2022-05-20T17:33:31.675667","exception":false,"start_time":"2022-05-20T17:33:31.322626","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"markdown","source":"interp.confusion","metadata":{"papermill":{"duration":0.359996,"end_time":"2022-05-20T17:33:32.392891","exception":false,"start_time":"2022-05-20T17:33:32.032895","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"interp.plot_confusion_matrix()","metadata":{"papermill":{"duration":1.234249,"end_time":"2022-05-20T17:33:33.989825","exception":false,"start_time":"2022-05-20T17:33:32.755576","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Do you see any clear patterns in the confusion matrix?\n\n2. Can you find any poor quality images?\n\n3. Where Does this First Run Strengthen your Hypothesis?\n\n4. What is a file path? What information does it contain?\n    - A. A file path always refers to a folder on a computer, it can contain many files inside of it\n    - B. A file path the location of a file or directory in a file system, it tells the computer where to look for a particular file\n    - C. A file path is the name of a file, and doesn't include the parent directories e.g. image3.jpg\n\n5. What does the working/current directory mean? Why is it important to know this when using Jupyter Notebook? \n    - A. It is the directory/folder that the user is currently working in. The file paths in your program are relative to your working directory\n    - B. It is the equivalent of the home directory/folder. It is the base of the file tree.\n    - C. AI can figure this out, don't worry because it is intelligent. \n\n6. Where can one extract the labels from a dataset of images zipped together in a file tree? What is the most common place, where is also oless common?\n    - A. The home directory\n    - B. Inside of the file path e.g. Cars/Sedan/5316.jpg\n    - C. Inside of a column in a table of metadata\n    - D. The file extension\n\t","metadata":{"papermill":{"duration":0.359819,"end_time":"2022-05-20T17:33:45.566735","exception":false,"start_time":"2022-05-20T17:33:45.206916","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}}]}